import tensorflow as tf  # Import TensorFlow library for deep learning tasks
import matplotlib.image as img  # Import matplotlib for image reading
import numpy as np  # Import NumPy for numerical operations
from collections import defaultdict  # Import defaultdict for creating dictionaries with default values
import collections  # Import collections module for collection data types
from shutil import copy  # Import shutil for high-level file operations
from shutil import copytree, rmtree  # Import shutil for directory copying and removal
import tensorflow.keras.backend as K  # Import Keras backend functions
from tensorflow.keras.models import load_model  # Import Keras function for loading pre-trained models
from tensorflow.keras.preprocessing import image  # Import Keras for image preprocessing
import matplotlib.pyplot as plt  # Import matplotlib for visualization
import os  # Import os module for operating system functions
import random  # Import random module for generating random numbers
import cv2  # Import OpenCV for image processing
from tensorflow.keras import regularizers  # Import regularizers for regularization techniques
from tensorflow.keras.applications.inception_v3 import InceptionV3  # Import pre-trained InceptionV3 model
from tensorflow.keras.models import Sequential, Model  # Import Sequential and Model for building neural network models
from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten  # Import layers for building neural network architectures
from tensorflow.keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D, AveragePooling2D  # Import layers for building convolutional neural networks
from tensorflow.keras.preprocessing.image import ImageDataGenerator  # Import ImageDataGenerator for data augmentation
from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger  # Import callbacks for model saving and logging
from tensorflow.keras.optimizers import SGD  # Import SGD optimizer for training models
from tensorflow.keras.regularizers import l2  # Import L2 regularization
from tensorflow import keras  # Import Keras for deep learning tasks
from tensorflow.keras import models  # Import Keras for building neural network models
import zipfile
import os
​
add Codeadd Markdown

Step 1.2 | Checking State of GPU
⬆️ Tabel of Contents

add Codeadd Markdown
# Check TensorFlow version
print(tf.__version__)
​
# Check GPU device name
print(tf.test.gpu_device_name())
​
add Codeadd Markdown

Step 1.3 | Changing Directory
⬆️ Tabel of Contents

add Codeadd Markdown
%cd /kaggle/input/food-101/
add Codeadd Markdown

Step 1.4 | Downloading and Extracting the Dataset
⬆️ Tabel of Contents

add Codeadd Markdown
def get_data_extract():
    """
    Check if the dataset exists, and if not, download and extract it.
    """
    if "food-101" in os.listdir():
        print("Dataset already exists")
    else:
        print("Downloading the data...")
        !wget http://data.vision.ee.ethz.ch/cvl/food-101.tar.gz
        print("Dataset downloaded!")
        print("Extracting data..")
        !tar xzvf food-101.tar.gz
        print("Extraction done!")
​
add Codeadd Markdown
# Download data and extract it to folder
# Uncomment this below line if you are on Colab
​
get_data_extract()
add Codeadd Markdown

Step 2 | Data Exploration and Verification

⬆️ Tabel of Contents

add Codeadd Markdown
# Check the extracted dataset folder
!ls food-101/
add Codeadd Markdown
The dataset being used is Food 101
This dataset has 101000 images in total. It's a food dataset with 101 categories(multiclass)
Each type of food has 750 training samples and 250 test samples
Note found on the webpage of the dataset :
On purpose, the training images were not cleaned, and thus still contain some amount of noise. This comes mostly in the form of intense colors and sometimes wrong labels.
All images were rescaled to have a maximum side length of 512 pixels.
The entire dataset is 5GB in size
add Codeadd Markdown

Step 2.1 | Understanding the Structure of Image Data
⬆️ Tabel of Contents

add Codeadd Markdown
os.listdir('food-101/images')
add Codeadd Markdown

Step 2.2 | Understanding the Metadata or Additional Information
⬆️ Tabel of Contents Understanding the Metadata or Additional Information

add Codeadd Markdown
os.listdir('food-101/meta')
add Codeadd Markdown
!head food-101/meta/train.txt
​
add Codeadd Markdown
!head food-101/meta/classes.txt
add Codeadd Markdown

Step 3 | Data Visualization

⬆️ Tabel of Contents

add Codeadd Markdown
# Define the number of rows and columns for the subplot grid
rows = 17
cols = 6
​
# Create a subplot grid with specified size
fig, ax = plt.subplots(rows, cols, figsize=(25,25))
​
# Set the title of the plot
fig.suptitle("Showing one random image from each class", y=1.05, fontsize=24)
​
# Define the directory containing the image data
data_dir = "food-101/images/"
​
# Get a sorted list of food class names
foods_sorted = sorted(os.listdir(data_dir))
​
# Initialize food_id variable
food_id = 0
​
# Loop through rows and columns to display images
for i in range(rows):
    for j in range(cols):
        try:
            food_selected = foods_sorted[food_id] 
            food_id += 1
        except:
            break
        if food_selected == '.DS_Store':
            continue
        # Get a list of images for the current food class
        food_selected_images = os.listdir(os.path.join(data_dir, food_selected))
        # Select a random image from the list
        food_selected_random = np.random.choice(food_selected_images)
        # Read and display the image
        img = plt.imread(os.path.join(data_dir, food_selected, food_selected_random))
        ax[i][j].imshow(img)
        ax[i][j].set_title(food_selected, pad=10)  # Set the title of the subplot
        
# Remove x and y ticks from all subplots
plt.setp(ax, xticks=[], yticks=[])
​
# Adjust the layout of subplots to fit the figure
plt.tight_layout()
​
add Codeadd Markdown

Step 4 | Data Preprocessing

⬆️ Tabel of Contents

add Codeadd Markdown

Step 4.1 | Data Splitting for Training and Test
⬆️ Tabel of Contents

add Codeadd Markdown
# Helper method to split dataset into train and test folders
def prepare_data(filepath, src, dest):
    # Create a dictionary to store image paths for each class
    classes_images = defaultdict(list)
    
    # Read the filepath and extract image paths
    with open(filepath, 'r') as txt:
        paths = [read.strip() for read in txt.readlines()]
        for p in paths:
            food = p.split('/')
            classes_images[food[0]].append(food[1] + '.jpg')
​
    # Iterate over classes and copy images to destination folder
    for food in classes_images.keys():
        print("\nCopying images into ", food)
        if not os.path.exists(os.path.join(dest, food)):
            os.makedirs(os.path.join(dest, food))
        for i in classes_images[food]:
            copy(os.path.join(src, food, i), os.path.join(dest, food, i))
    print("Copying Done!")
​
add Codeadd Markdown

Step 4.2 | Prepares the Train Dataset 
⬆️ Tabel of Contents

add Codeadd Markdown
# Change current directory to the root directory
%cd /
​
# Print message indicating the start of creating train data
print("Creating train data...")
​
# Call prepare_data function to copy images from train.txt to train directory
prepare_data('/kaggle/input/food-101/food-101/meta/train.txt', '/kaggle/input/food-101/food-101/images', 'train')
​
add Codeadd Markdown

Step 4.3 | Creating the Test Data 
⬆️ Tabel of Contents

add Codeadd Markdown
# Print message indicating the start of creating test data
print("Creating test data...")
​
# Call prepare_data function to copy images from test.txt to test directory
prepare_data('/kaggle/input/food-101/food-101/meta/test.txt', '/kaggle/input/food-101/food-101/images', 'test')
​
add Codeadd Markdown

Step 4.4 | Counting the Files and Directories in "Train" Folder 
⬆️ Tabel of Contents

add Codeadd Markdown
# Print message indicating the total number of samples in the train folder
print("Total number of samples in train folder")
​
# Execute the find command to search for files and directories in the train folder
# -type d: Search for directories
# -or: Logical OR operator
# -type f: Search for regular files
# -printf '.': Print a single character for each file or directory found
# wc -c: Count the number of characters (which corresponds to the number of files and directories)
!find train -type d -or -type f -printf '.' | wc -c
​
add Codeadd Markdown

Step 4.5 | Counting the Files and Directories in "Test" Folder 
⬆️ Tabel of Contents

add Codeadd Markdown
# Print message indicating the total number of samples in the test folder
print("Total number of samples in test folder")
​
# Execute the find command to search for files and directories in the test folder
# -type d: Search for directories
# -or: Logical OR operator
# -type f: Search for regular files
# -printf '.': Print a single character for each file or directory found
# wc -c: Count the number of characters (which corresponds to the number of files and directories)
!find test -type d -or -type f -printf '.' | wc -c
​
add Codeadd Markdown
We now have train and test data ready
But to experiment and try different architectures, working on the whole data with 101 classes takes a lot of time and computation
To proceed with further experiments, I am creating train_min and test_mini, limiting the dataset to 3 classes
Since the original problem is multiclass classification which makes key aspects of architectural decisions different from that of binary classification, choosing 3 classes is a good start instead of 2
add Codeadd Markdown

Step 4.6 | Removing the .DS_Store Entry 
⬆️ Tabel of Contents

add Codeadd Markdown
# List of all 101 types of foods(sorted alphabetically)
del foods_sorted[0] # remove .DS_Store from the list
add Codeadd Markdown
print(foods_sorted)
​
add Codeadd Markdown

Step 4.7 | Creaing Subset 
⬆️ Tabel of Contents

add Codeadd Markdown
# Helper method to create train_mini and test_mini data samples
def dataset_mini(food_list, src, dest):
    # Check if the destination directory exists
    if os.path.exists(dest):
        # If it exists, remove it to ensure a clean slate
        rmtree(dest)  # Removing dataset_mini (if it already exists) folders
    # Create the destination directory
    os.makedirs(dest)
    
    # Iterate over each food item in the provided list
    for food_item in food_list:
        print("Copying images into", food_item)
        # Recursively copy the images from the source directory to the destination directory for each food item
        copytree(os.path.join(src, food_item), os.path.join(dest, food_item))
​
add Codeadd Markdown
# List of food items for creating mini datasets
food_list = ['apple_pie', 'pizza', 'omelette']
​
# Source and destination directories for train and test datasets
src_train = 'train'
dest_train = 'train_mini'
src_test = 'test'
dest_test = 'test_mini'
​
# Create train_mini dataset
dataset_mini(food_list, src_train, dest_train)
​
# Create test_mini dataset
dataset_mini(food_list, src_test, dest_test)
​
add Codeadd Markdown
# Print message indicating the creation of the train data folder with new classes
print("Creating train data folder with new classes")
​
# Create train_mini dataset with specified food classes
dataset_mini(food_list, src_train, dest_train)
​
add Codeadd Markdown
# Print message indicating the total number of samples in the train folder
print("Total number of samples in train folder")
​
# Execute the find command to search for files and directories in the train_mini folder
# -type d: Search for directories
# -or: Logical OR operator
# -type f: Search for regular files
# -printf '.': Print a single character for each file or directory found
# wc -c: Count the number of characters (which corresponds to the number of files and directories)
!find train_mini -type d -or -type f -printf '.' | wc -c
​
add Codeadd Markdown
# Print message indicating the creation of the test data folder with new classes
print("Creating test data folder with new classes")
​
# Create test_mini dataset with specified food classes
dataset_mini(food_list, src_test, dest_test)
​
add Codeadd Markdown
# Print message indicating the total number of samples in the test folder
print("Total number of samples in test folder")
​
# Execute the find command to search for files and directories in the test_mini folder
# -type d: Search for directories
# -or: Logical OR operator
# -type f: Search for regular files
# -printf '.': Print a single character for each file or directory found
# wc -c: Count the number of characters (which corresponds to the number of files and directories)
!find test_mini -type d -or -type f -printf '.' | wc -c
​
add Codeadd Markdown

Step 5 | Training Neural Network Model for Image Classification

⬆️ Tabel of Contents

add Codeadd Markdown
Keras and other Deep Learning libraries provide pretrained models
These are deep neural networks with efficient architectures(like VGG,Inception,ResNet) that are already trained on datasets like ImageNet
Using these pretrained models, we can use the already learned weights and add few layers on top to finetune the model to our new data
This helps in faster convergance and saves time and computation when compared to models trained from scratch
add Codeadd Markdown
We currently have a subset of dataset with 3 classes - samosa, pizza and omelette
Use the below code to finetune Inceptionv3 pretrained model
add Codeadd Markdown

Fine tune Inception Pretrained model using Food 101 dataset

⬆️ Tabel of Contents

add Codeadd Markdown
# Clear Keras session to release resources
K.clear_session()
​
# Number of classes in the dataset
n_classes = 3
​
# Image dimensions
img_width, img_height = 299, 299
​
# Directories for training and validation data
train_data_dir = 'train_mini'
validation_data_dir = 'test_mini'
​
# Number of samples in the training and validation sets
nb_train_samples = 2250  # Number of training samples
nb_validation_samples = 750  # Number of validation samples
​
# Batch size for training
batch_size = 16
​
# Data augmentation and normalization for training images
train_datagen = ImageDataGenerator(
    rescale=1. / 255,  # Normalize pixel values to the range [0,1]
    shear_range=0.2,   # Shear transformation
    zoom_range=0.2,    # Random zoom
    horizontal_flip=True)  # Horizontal flip
​
# Normalization for validation images
test_datagen = ImageDataGenerator(rescale=1. / 255)  # Normalize pixel values to the range [0,1]
​
# Generate batches of training data
train_generator = train_datagen.flow_from_directory(
    train_data_dir,  # Path to the training data directory
    target_size=(img_height, img_width),  # Resize images to match the input size of the model
    batch_size=batch_size,  # Number of samples per batch
    class_mode='categorical')  # Use categorical labels for multi-class classification
​
# Generate batches of validation data
validation_generator = test_datagen.flow_from_directory(
    validation_data_dir,  # Path to the validation data directory
    target_size=(img_height, img_width),  # Resize images to match the input size of the model
    batch_size=batch_size,  # Number of samples per batch
    class_mode='categorical')  # Use categorical labels for multi-class classification
​
# Load the pre-trained InceptionV3 model without the top layers
inception = InceptionV3(weights='imagenet', include_top=False)
​
# Add custom top layers for fine-tuning
x = inception.output  # Output tensor of the InceptionV3 model
x = GlobalAveragePooling2D()(x)  # Global average pooling layer
x = Dense(128, activation='relu')(x)  # Fully connected layer with ReLU activation
x = Dropout(0.2)(x)  # Dropout layer for regularization
​
# Predictions layer with softmax activation for class probabilities
predictions = Dense(3, kernel_regularizer=regularizers.l2(0.005), activation='softmax')(x)
​
# Create the final model with InceptionV3 as the base and custom top layers
model = Model(inputs=inception.input, outputs=predictions)
​
# Compile the model with SGD optimizer, categorical cross-entropy loss, and accuracy metric
model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])
​
# Define callbacks for saving the best model and logging training history
checkpointer = ModelCheckpoint(filepath='best_model_3class.hdf5', verbose=1, save_best_only=True)
csv_logger = CSVLogger('history_3class.log')
​
# Train the model using the training and validation generators
history = model.fit_generator(
    train_generator,
    steps_per_epoch=nb_train_samples // batch_size,  # Number of batches per epoch
    validation_data=validation_generator,
    validation_steps=nb_validation_samples // batch_size,  # Number of validation batches per epoch
    epochs=30,  # Number of training epochs
    verbose=1,  # Verbosity mode (0=silent, 1=progress bar, 2=one line per epoch)
    callbacks=[csv_logger, checkpointer])  # List of callbacks for training
​
# Save the trained model
model.save('model_trained_3class.hdf5')  # Save the model to HDF5 file format
​
add Codeadd Markdown

Step 5.1 | Obtaining the Class Indices Mapping 
⬆️ Tabel of Contents

add Codeadd Markdown
# Get the class indices mapping for the labels in the training data generator
class_map_3 = train_generator.class_indices
​
# Display the class indices mapping
class_map_3
​
add Codeadd Markdown

Step 5.2 | Visualizing the Training and Validation Accuracy 
⬆️ Tabel of Contents

add Codeadd Markdown
def plot_accuracy(history, title):
    """
    Plot training and validation accuracy over epochs.
    
    Args:
    - history: Training history obtained from model training
    - title: Title of the plot
    
    Returns:
    - None
    """
    plt.title(title)
    plt.plot(history.history['acc'])
    plt.plot(history.history['val_acc'])
    plt.ylabel('accuracy')
    plt.xlabel('epoch')
    plt.legend(['train_accuracy', 'validation_accuracy'], loc='best')
    plt.show()
​
def plot_loss(history, title):
    """
    Plot training and validation loss over epochs.
    
    Args:
    - history: Training history obtained from model training
    - title: Title of the plot
    
    Returns:
    - None
    """
    plt.title(title)
    plt.plot(history.history['loss'])
    plt.plot(history.history['val_loss'])
    plt.ylabel('loss')
    plt.xlabel('epoch')
    plt.legend(['train_loss', 'validation_loss'], loc='best')
    plt.show()
​
add Codeadd Markdown

Step 5.3 | Model Evaluation 
⬆️ Tabel of Contents

add Codeadd Markdown
plot_accuracy(history, 'FOOD101-Inceptionv3')  # Plot training and validation accuracy
plot_loss(history, 'FOOD101-Inceptionv3')      # Plot training and validation loss
​
add Codeadd Markdown
The plots show that the accuracy of the model increased with epochs and the loss has decreased

Validation accuracy has been on the higher side than training accuracy for many epochs This could be for several reasons:

We used a pretrained model trained on ImageNet which contains data from a variety of classes

Using dropout can lead to a higher validation accuracy

add Codeadd Markdown
%%time
# Loading the best saved model to make predictions
K.clear_session()  # Clear Keras session
model_best = load_model('best_model_3class.hdf5', compile=False)  # Load the best saved model
​
add Codeadd Markdown
Setting compile=False and clearing the session leads to faster loading of the saved model
Withouth the above addiitons, model loading was taking more than a minute!
add Codeadd Markdown

Step 5.4 | Predicting Class Label 
⬆️ Tabel of Contents

add Codeadd Markdown
def predict_class(model, images, show=True):
    """
    Predict the class label for each image in the given list of image paths.
    
    Args:
    - model: Trained model for making predictions
    - images: List of image paths
    - show: Boolean flag to control image display
    
    Returns:
    - None
    """
    for img in images:
        img = image.load_img(img, target_size=(299, 299))  # Load image and resize to model's input size
        img = image.img_to_array(img)                     # Convert image to numpy array
        img = np.expand_dims(img, axis=0)                 # Add batch dimension
        img /= 255.                                       # Normalize pixel values
​
        pred = model.predict(img)                         # Make prediction
        index = np.argmax(pred)                           # Get the index of the class with the highest probability
        food_list.sort()                                  # Sort the list of food items
        pred_value = food_list[index]                     # Get the predicted class label
        
        if show:
            plt.imshow(img[0])                           # Display the image
            plt.axis('off')
            plt.title(pred_value)                        # Set title as the predicted class label
            plt.show()
​
add Codeadd Markdown

Step 5.5 | Downloading Images from the Internet
⬆️ Tabel of Contents

add Codeadd Markdown
# Downloading images from internet using the URLs
!wget -O samosa.jpg http://veggiefoodrecipes.com/wp-content/uploads/2016/05/lentil-samosa-recipe-01.jpg
!wget -O applepie.jpg https://acleanbake.com/wp-content/uploads/2017/10/Paleo-Apple-Pie-with-Crumb-Topping-gluten-free-grain-free-dairy-free-15.jpg
!wget -O pizza.jpg http://104.130.3.186/assets/itemimages/400/400/3/default_9b4106b8f65359684b3836096b4524c8_pizza%20dreamstimesmall_94940296.jpg
!wget -O omelette.jpg https://www.incredibleegg.org/wp-content/uploads/basic-french-omelet-930x550.jpg
​
add Codeadd Markdown
# Make a list of downloaded images
images = ['applepie.jpg', 'pizza.jpg', 'omelette.jpg']
​
# Test the trained model
predict_class(model_best, images, True)
​
​
add Codeadd Markdown
Yes!!! The model got them all right!!
add Codeadd Markdown

Fine tune Inceptionv3 model with 11 classes of data

⬆️ Tabel of Contents

add Codeadd Markdown
We trained a model on 3 classes and tested it using new data
The model was able to predict the classes of all three test images correctly
Will it be able to perform at the same level of accuracy for more classes?
FOOD-101 dataset has 101 classes of data
Even with fine tuning using a pre-trained model, each epoch was taking more than an hour when all 101 classes of data is used(tried this on both Colab and on a Deep Learning VM instance with P100 GPU on GCP)
But to check how the model performs when more classes are included, I'm using the same model to fine tune and train on 11 randomly chosen classes
add Codeadd Markdown
def pick_n_random_classes(n):
    """
    Select n random food classes from the sorted list of food items.
    
    Args:
    - n: Number of random food classes to select
    
    Returns:
    - List of n randomly selected food classes
    """
    food_list = []
    random_food_indices = random.sample(range(len(foods_sorted)), n)  # Sample n random indices
    for i in random_food_indices:
        food_list.append(foods_sorted[i])  # Retrieve corresponding food items
    food_list.sort()  # Sort the list of randomly selected food classes
    return food_list
​
add Codeadd Markdown
n = 11  # Number of random food classes to select
food_list = pick_n_random_classes(n)  # Select n random food classes
food_list = ['apple_pie', 'beef_carpaccio', 'bibimbap', 'cup_cakes', 'foie_gras', 'french_fries', 'garlic_bread', 'pizza', 'spring_rolls', 'spaghetti_carbonara', 'strawberry_shortcake']
print("These are the randomly picked food classes we will be training the model on...\n", food_list)
​
add Codeadd Markdown
# Print a message indicating the start of the process
print("Creating training data folder with new classes...")
​
# Call the dataset_mini function to create a new data subset with the selected food classes for training
dataset_mini(food_list, src_train, dest_train)
​
add Codeadd Markdown
# Print the total number of samples in the train folder
print("Total number of samples in train folder")
​
# Count the number of files and directories in the train_mini folder and print the count
!find train_mini -type d -or -type f -printf '.' | wc -c
​
add Codeadd Markdown
# Print a message indicating the start of the process
print("Creating test data folder with new classes")
​
# Call the dataset_mini function to create a new data subset with the selected food classes for testing
dataset_mini(food_list, src_test, dest_test)
​
add Codeadd Markdown
# Print a message indicating the start of the process
print("Total number of samples in test folder")
​
# Count the number of files and directories in the test_mini folder and print the count
!find test_mini -type d -or -type f -printf '.' | wc -c
​
add Codeadd Markdown
# Clear any previous sessions to free up memory
K.clear_session()
​
# Set the number of classes
n_classes = n
​
# Set the dimensions of input images
img_width, img_height = 299, 299
​
# Set the paths for the training and validation data directories
train_data_dir = 'train_mini'
validation_data_dir = 'test_mini'
​
# Set the number of training and validation samples
nb_train_samples = 8250
nb_validation_samples = 2750
​
# Set the batch size for training
batch_size = 16
​
# Define data augmentation for training images
train_datagen = ImageDataGenerator(
    rescale=1. / 255,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True)
​
# Define data augmentation for validation images
test_datagen = ImageDataGenerator(rescale=1. / 255)
​
# Generate batches of augmented training and validation data
train_generator = train_datagen.flow_from_directory(
    train_data_dir,
    target_size=(img_height, img_width),
    batch_size=batch_size,
    class_mode='categorical')
​
validation_generator = test_datagen.flow_from_directory(
    validation_data_dir,
    target_size=(img_height, img_width),
    batch_size=batch_size,
    class_mode='categorical')
​
# Load the InceptionV3 model pretrained on ImageNet without the top layer
inception = InceptionV3(weights='imagenet', include_top=False)
​
# Add custom top layers for classification
x = inception.output
x = GlobalAveragePooling2D()(x)
x = Dense(128, activation='relu')(x)
x = Dropout(0.2)(x)
predictions = Dense(n, kernel_regularizer=regularizers.l2(0.005), activation='softmax')(x)
​
# Create the final model
model = Model(inputs=inception.input, outputs=predictions)
​
# Compile the model
model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])
​
# Define callbacks for model checkpointing and logging
checkpointer = ModelCheckpoint(filepath='best_model_11class.hdf5', verbose=1, save_best_only=True)
csv_logger = CSVLogger('history_11class.log')
​
# Train the model
history_11class = model.fit_generator(train_generator,
                    steps_per_epoch=nb_train_samples // batch_size,
                    validation_data=validation_generator,
                    validation_steps=nb_validation_samples // batch_size,
                    epochs=30,
                    verbose=1,
                    callbacks=[csv_logger, checkpointer])
​
# Save the trained model
model.save('model_trained_11class.hdf5')
​
add Codeadd Markdown
# Get the class indices for the 11 food classes from the training data generator
class_map_11 = train_generator.class_indices
class_map_11
​
add Codeadd Markdown
# Plot the accuracy over epochs for the training and validation sets
plot_accuracy(history_11class, 'FOOD101-Inceptionv3')
​
# Plot the loss over epochs for the training and validation sets
plot_loss(history_11class, 'FOOD101-Inceptionv3')
​
add Codeadd Markdown
The plots show that the accuracy of the model increased with epochs and the loss has decreased

Validation accuracy has been on the higher side than training accuracy for many epochs

This could be for several reasons:
We used a pretrained model trained on ImageNet which contains data from a variety of classes
Using dropout can lead to a higher validation accuracy
add Codeadd Markdown
%%time
# Clear any previous session and load the best saved model for predictions
K.clear_session()
model_best = load_model('best_model_11class.hdf5', compile=False)
​
add Codeadd Markdown
# Downloading images from internet using the URLs
!wget -O cupcakes.jpg https://www.publicdomainpictures.net/pictures/110000/nahled/halloween-witch-cupcakes.jpg
!wget -O springrolls.jpg https://upload.wikimedia.org/wikipedia/commons/6/6f/Vietnamese_spring_rolls.jpg
!wget -O pizza.jpg http://104.130.3.186/assets/itemimages/400/400/3/default_9b4106b8f65359684b3836096b4524c8_pizza%20dreamstimesmall_94940296.jpg
!wget -O garlicbread.jpg https://c1.staticflickr.com/1/84/262952165_7ba3466108_z.jpg?zz=1
​
# If you have an image in your local computer and want to try it, uncomment the below code to upload the image files
​
​
# from google.colab import files
# image = files.upload()
add Codeadd Markdown
# Make a list of downloaded images and test the trained model
images = []
images.append('cupcakes.jpg')
images.append('pizza.jpg')
images.append('springrolls.jpg')
images.append('garlicbread.jpg')
predict_class(model_best, images, True)
